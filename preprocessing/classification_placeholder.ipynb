{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7160da45",
      "metadata": {
        "id": "7160da45"
      },
      "source": [
        "# Classification Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a6f11e",
      "metadata": {
        "id": "81a6f11e"
      },
      "outputs": [],
      "source": [
        "import flair\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "# load tagger\n",
        "tagger = SequenceTagger.load(\"flair/ner-english-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77adacd3",
      "metadata": {
        "id": "77adacd3"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f571c8d",
      "metadata": {
        "id": "0f571c8d"
      },
      "outputs": [],
      "source": [
        "def replace_entities_placeholder_flair(text):\n",
        "    # make example sentence\n",
        "    sentence = Sentence(text)\n",
        "    # predict NER tags\n",
        "    tagger.predict(sentence)\n",
        "    # iterate over entities and print\n",
        "    replacements = []\n",
        "    if not sentence.get_spans('ner'):\n",
        "        return text\n",
        "\n",
        "    for entity in sentence.get_spans('ner'):\n",
        "        if entity.get_label().value == \"ORG\":\n",
        "            repl = \"ORG\"\n",
        "            replacements.append((entity.start_position, entity.end_position, repl, entity.text))\n",
        "        elif entity.get_label().value == \"PER\":\n",
        "            repl = \"PERSON\"\n",
        "            replacements.append((entity.start_position, entity.end_position, repl, entity.text))\n",
        "        elif entity.get_label().value == \"LOC\":\n",
        "            repl = \"LOCATION\"\n",
        "            replacements.append((entity.start_position, entity.end_position, repl, entity.text))\n",
        "\n",
        "    if replacements:\n",
        "        res = []\n",
        "        i = 0\n",
        "        for (start, end, txt, orig) in replacements:\n",
        "            assert orig != txt\n",
        "            res.append(text[i:start] + txt)\n",
        "            i = end\n",
        "        res.append(text[end:])\n",
        "        return ''.join(res)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ec94168",
      "metadata": {
        "tags": [],
        "id": "0ec94168"
      },
      "outputs": [],
      "source": [
        "cls_data = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25ee403d",
      "metadata": {
        "tags": [],
        "id": "25ee403d"
      },
      "outputs": [],
      "source": [
        "cls_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ab197dd",
      "metadata": {
        "tags": [],
        "id": "2ab197dd"
      },
      "outputs": [],
      "source": [
        "train_data = cls_data['train']\n",
        "unsup_data = cls_data['unsupervised']\n",
        "test_data = cls_data['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be03cfa6",
      "metadata": {
        "tags": [],
        "id": "be03cfa6"
      },
      "outputs": [],
      "source": [
        "train_data[5]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "244e6606",
      "metadata": {
        "id": "244e6606"
      },
      "outputs": [],
      "source": [
        "replace_entities_placeholder_flair(train_data[10]['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d224c49",
      "metadata": {
        "tags": [],
        "id": "3d224c49"
      },
      "outputs": [],
      "source": [
        "train_pairs_placeholder = []\n",
        "with open(\"anonymized_flair/classification_placeholder/imdb_train.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"text\",\"label\"])\n",
        "    for p in tqdm(train_data):\n",
        "        src = replace_entities_placeholder_flair(p['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
        "        train_pairs_placeholder.append((src, p['label']))\n",
        "        writer.writerow((src, p['label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f1c557",
      "metadata": {
        "id": "e4f1c557"
      },
      "outputs": [],
      "source": [
        "test_pairs_placeholder = []\n",
        "with open(\"anonymized_flair/classification_placeholder/imdb_test.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"text\",\"label\"])\n",
        "    for p in tqdm(test_data):\n",
        "        src = replace_entities_placeholder_flair(p['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
        "        test_pairs_placeholder.append((src, p['label']))\n",
        "        writer.writerow((src, p['label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cebd1177",
      "metadata": {
        "id": "cebd1177"
      },
      "outputs": [],
      "source": [
        "unsup_pairs_placeholder = []\n",
        "with open(\"anonymized_flair/classification_placeholder/imdb_unsup.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"text\",\"label\"])\n",
        "    for p in tqdm(unsup_data):\n",
        "        src = replace_entities_placeholder_flair(p['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
        "        unsup_pairs_placeholder.append((src, p['label']))\n",
        "        writer.writerow((src, p['label']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01ea0559",
      "metadata": {
        "id": "01ea0559"
      },
      "source": [
        "# Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e3cff6",
      "metadata": {
        "id": "34e3cff6"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2f7ead",
      "metadata": {
        "id": "6e2f7ead"
      },
      "outputs": [],
      "source": [
        "def replace_entities_placeholder_spacy(text):\n",
        "    parsed = nlp(text)\n",
        "    # iterate over entities and print\n",
        "    replacements = []\n",
        "    if all([w.ent_type == 0 for w in parsed]):\n",
        "        return text\n",
        "\n",
        "    for word in parsed:\n",
        "        if word.ent_type_ == \"ORG\":\n",
        "            repl = \"ORG\"\n",
        "            replacements.append((word.idx, word.idx + len(word.text), repl, word.text))\n",
        "        elif word.ent_type_ == \"PERSON\":\n",
        "            repl = \"PERSON\"\n",
        "            replacements.append((word.idx, word.idx + len(word.text), repl, word.text))\n",
        "        elif word.ent_type_ == \"GPE\":\n",
        "            repl = \"LOCATION\"\n",
        "            replacements.append((word.idx, word.idx + len(word.text), repl, word.text))\n",
        "\n",
        "    if replacements:\n",
        "        res = []\n",
        "        i = 0\n",
        "        for (start, end, txt, orig) in replacements:\n",
        "            assert orig != txt\n",
        "            res.append(text[i:start] + txt)\n",
        "            i = end\n",
        "        res.append(text[end:])\n",
        "        return ''.join(res)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aafabdc3",
      "metadata": {
        "id": "aafabdc3"
      },
      "source": [
        "# IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "541c5de4",
      "metadata": {
        "id": "541c5de4"
      },
      "outputs": [],
      "source": [
        "train_pairs_placeholder2 = []\n",
        "with open(\"anonymized_spacy/classification_placeholder/imdb_train.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"text\",\"label\"])\n",
        "    for p in tqdm(train_data):\n",
        "        src = replace_entities_placeholder_spacy(p['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
        "        train_pairs_placeholder2.append((src, p['label']))\n",
        "        writer.writerow((src, p['label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9908c61f",
      "metadata": {
        "id": "9908c61f"
      },
      "outputs": [],
      "source": [
        "test_pairs_placeholder2 = []\n",
        "with open(\"anonymized_spacy/classification_placeholder/imdb_test.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"text\",\"label\"])\n",
        "    for p in tqdm(test_data):\n",
        "        src = replace_entities_placeholder_spacy(p['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
        "        test_pairs_placeholder2.append((src, p['label']))\n",
        "        writer.writerow((src, p['label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13f7bfb2",
      "metadata": {
        "id": "13f7bfb2"
      },
      "outputs": [],
      "source": [
        "unsup_pairs_placeholder2 = []\n",
        "with open(\"anonymized_spacy/classification_placeholder/imdb_unsup.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"text\",\"label\"])\n",
        "    for p in tqdm(unsup_data):\n",
        "        src = replace_entities_placeholder_spacy(p['text'].replace(\"<br /><br />\", \" \").replace(\"<br />\", \"\"))\n",
        "        unsup_pairs_placeholder2.append((src, p['label']))\n",
        "        writer.writerow((src, p['label']))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}